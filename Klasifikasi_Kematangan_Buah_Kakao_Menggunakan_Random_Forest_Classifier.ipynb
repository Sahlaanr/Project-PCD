{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {
        "id": "MTXNQtFl61lV"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
        "from skimage.feature import graycomatrix, graycoprops"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Pre-Processing"
      ],
      "metadata": {
        "id": "rFqIineur3V-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Konversi gambar ke grayscale tanpa library\n",
        "def convert_to_grayscale(image):\n",
        "    grayscale_image = np.dot(image[..., :3], [0.2989, 0.5870, 0.1140])\n",
        "    return grayscale_image.astype(np.uint8)"
      ],
      "metadata": {
        "id": "FStPRb2z6-ye"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Reduksi noise menggunakan mean filter\n",
        "def apply_mean_filter(image):\n",
        "    kernel = np.ones((3, 3)) / 9\n",
        "    filtered_image = np.zeros_like(image)\n",
        "    for i in range(1, image.shape[0] - 1):\n",
        "        for j in range(1, image.shape[1] - 1):\n",
        "            filtered_image[i, j] = np.sum(kernel * image[i-1:i+2, j-1:j+2])\n",
        "    return filtered_image"
      ],
      "metadata": {
        "id": "niFay5upsDP-"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Peningkatan kontras mengunakan histogram equalization\n",
        "def histogram_equalization(image):\n",
        "    hist, bins = np.histogram(image.flatten(), 256, [0, 256])\n",
        "    cdf = hist.cumsum()\n",
        "    cdf_normalized = cdf * hist.max() / cdf.max()\n",
        "    cdf = (cdf - cdf.min()) * 255 / (cdf.max() - cdf.min())\n",
        "    cdf = cdf.astype('uint8')\n",
        "    return cdf[image]"
      ],
      "metadata": {
        "id": "fmcZT6--sD3x"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline pre-processing gambar dengan membaca dimensi gambar secara dinamis\n",
        "def preprocess_image_manual(image_path):\n",
        "    # Membaca gambar menggunakan Pillow untuk mendapatkan dimensi\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize((224, 224))  # Resize gambar ke (224, 224) jika diperlukan\n",
        "        image = np.array(img)  # Konversi ke numpy array (RGB)\n",
        "\n",
        "    # Pastikan gambar memiliki 3 channel\n",
        "    if image.ndim == 2:  # Jika grayscale\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "    elif image.shape[2] == 4:  # Jika RGBA\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    # Pre-processing manual\n",
        "    grayscale = convert_to_grayscale(image)\n",
        "    noise_reduced = apply_mean_filter(grayscale)\n",
        "    enhanced = histogram_equalization(noise_reduced)\n",
        "    return enhanced"
      ],
      "metadata": {
        "id": "maKTy6yhsHH_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Extraction"
      ],
      "metadata": {
        "id": "3f3rpzWysWjh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Ekstraksi fitur menggunakan GLCM dan Shape descriptors\n",
        "def extract_features(image):\n",
        "    # Texture features using GLCM\n",
        "    glcm = graycomatrix(image, distances=[1], angles=[0], levels=256, symmetric=True, normed=True)\n",
        "    contrast = graycoprops(glcm, 'contrast')[0, 0]\n",
        "    energy = graycoprops(glcm, 'energy')[0, 0]\n",
        "    homogeneity = graycoprops(glcm, 'homogeneity')[0, 0]\n",
        "\n",
        "    # Shape features\n",
        "    _, binary = cv2.threshold(image, 127, 255, cv2.THRESH_BINARY)\n",
        "    contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
        "    if contours:\n",
        "        cnt = contours[0]\n",
        "        area = cv2.contourArea(cnt)\n",
        "        perimeter = cv2.arcLength(cnt, True)\n",
        "        circularity = (4 * np.pi * area) / (perimeter ** 2) if perimeter > 0 else 0\n",
        "    else:\n",
        "        area, perimeter, circularity = 0, 0, 0\n",
        "\n",
        "    return [contrast, energy, homogeneity, area, perimeter, circularity]"
      ],
      "metadata": {
        "id": "N09X-1o27BOY"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Klasifikasi Menggunakan RandomForest Classifier"
      ],
      "metadata": {
        "id": "Byf3rOJQsaCf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Klasifikasi data menggunakan RandomForest\n",
        "def classify_images(features, labels):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "    classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "    classifier.fit(X_train, y_train)\n",
        "    y_pred = classifier.predict(X_test)\n",
        "\n",
        "    #Metrik Evaluasi\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1"
      ],
      "metadata": {
        "id": "_ceINrYS7FC9"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Main Program"
      ],
      "metadata": {
        "id": "uFNQdZRrtDVk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Cocoa Ripeness Dataset\"\n",
        "categories = ['mentah', 'matang', 'terlalu_matang']\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "# Pre-process and extract features untuk semua citra gambar\n",
        "for category in categories:\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    label = categories.index(category)\n",
        "\n",
        "    for image_name in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_name)\n",
        "        preprocessed_image = preprocess_image_manual(image_path)\n",
        "        feature_vector = extract_features(preprocessed_image)\n",
        "        features.append(feature_vector)\n",
        "        labels.append(label)"
      ],
      "metadata": {
        "id": "icPWfPGv7LUq"
      },
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Klasifikasi dan evaluasi\n",
        "accuracy, precision, recall, f1 = classify_images(features, labels)"
      ],
      "metadata": {
        "id": "bEV_lyCeVnKN"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Recall: {recall * 100:.2f}%\")\n",
        "print(f\"F1-Score: {f1 * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "srQ_s08bVrXe",
        "outputId": "8b227b0c-25f7-4bcc-8016-a70447f528ad"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 83.33%\n",
            "Precision: 79.59%\n",
            "Recall: 83.33%\n",
            "F1-Score: 80.01%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperimen 1"
      ],
      "metadata": {
        "id": "K3eSMU7ekLK3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "-Noise Reduction menggunakan gaussian blur (sebelumnya mean filter)\n",
        "\n",
        " -Penerapan augmentasi rotasi, flipping, dan perubahan brightness."
      ],
      "metadata": {
        "id": "_j_cst_MgnWm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random"
      ],
      "metadata": {
        "id": "4xIcMYK602U9"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Membuat gaussian kernel secara manual\n",
        "def gaussian_kernel(size, sigma=1):\n",
        "    kernel = np.zeros((size, size), dtype=np.float32)\n",
        "    center = size // 2\n",
        "    for i in range(size):\n",
        "        for j in range(size):\n",
        "            diff = (i - center) ** 2 + (j - center) ** 2\n",
        "            kernel[i, j] = np.exp(-diff / (2 * sigma ** 2))\n",
        "    kernel /= np.sum(kernel)\n",
        "    return kernel"
      ],
      "metadata": {
        "id": "qpUnNfaJjpaJ"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Noise reduction menggunakan gaussian blur\n",
        "def apply_gaussian_blur(image, kernel_size=3, sigma=1):\n",
        "    kernel = gaussian_kernel(kernel_size, sigma)\n",
        "    padded_image = np.pad(image, kernel_size // 2, mode='reflect')\n",
        "    blurred_image = np.zeros_like(image)\n",
        "\n",
        "    for i in range(image.shape[0]):\n",
        "        for j in range(image.shape[1]):\n",
        "            region = padded_image[i:i+kernel_size, j:j+kernel_size]\n",
        "            blurred_image[i, j] = np.sum(region * kernel)\n",
        "\n",
        "    return blurred_image.astype(np.uint8)"
      ],
      "metadata": {
        "id": "Kxlsli6FJf_6"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Melakukan augmentasi data dengan rotasi, flipping, dan perubahan brightness\n",
        "def augment_image(image):\n",
        "    augmented_images = []\n",
        "\n",
        "    #Rotasi 90 derajat\n",
        "    rotated_90 = np.rot90(image)\n",
        "    augmented_images.append(rotated_90)\n",
        "\n",
        "    #Rotasi 180 derajat\n",
        "    rotated_180 = np.rot90(image, k=2)\n",
        "    augmented_images.append(rotated_180)\n",
        "\n",
        "    #Flipping horizontal\n",
        "    flipped_horizontal = np.flip(image, axis=1)\n",
        "    augmented_images.append(flipped_horizontal)\n",
        "\n",
        "    #Flipping vertical\n",
        "    flipped_vertical = np.flip(image, axis=0)\n",
        "    augmented_images.append(flipped_vertical)\n",
        "\n",
        "    #Perubahan brightness\n",
        "    brightened = np.clip(image + random.randint(20, 50), 0, 255)\n",
        "    darkened = np.clip(image - random.randint(20, 50), 0, 255)\n",
        "    augmented_images.extend([brightened, darkened])\n",
        "\n",
        "    return augmented_images"
      ],
      "metadata": {
        "id": "h9CuVIM6JuSq"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Pipeline pre-processing gambar dengan augmentasi dan gaussian\n",
        "def preprocess_image_manual(image_path):\n",
        "    #Membaca gambar menggunakan Pillow untuk mendapatkan dimensi\n",
        "    with Image.open(image_path) as img:\n",
        "        img = img.resize((224, 224))  # Resize gambar ke (224, 224) jika diperlukan\n",
        "        image = np.array(img)  # Konversi ke numpy array (RGB)\n",
        "\n",
        "    #Pastikan gambar memiliki 3 channel\n",
        "    if image.ndim == 2:  # Jika grayscale\n",
        "        image = np.stack([image] * 3, axis=-1)\n",
        "    elif image.shape[2] == 4:  # Jika RGBA\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    #Pre-processing manual\n",
        "    grayscale = convert_to_grayscale(image)\n",
        "    noise_reduced = apply_gaussian_blur(grayscale, kernel_size=5, sigma=1.5)\n",
        "    enhanced = histogram_equalization(noise_reduced)\n",
        "\n",
        "    #Data augmentasi\n",
        "    augmented_images = augment_image(enhanced)\n",
        "\n",
        "    #Kembalikan semua gambar augmented\n",
        "    return augmented_images"
      ],
      "metadata": {
        "id": "zpLWidsnq9C5"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Cocoa Ripeness Dataset\"\n",
        "categories = ['mentah', 'matang', 'terlalu_matang']\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "#Pre-process and extract features untuk semua citra\n",
        "for category in categories:\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    label = categories.index(category)\n",
        "\n",
        "    for image_name in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_name)\n",
        "        preprocessed_image = preprocess_image_manual(image_path)\n",
        "\n",
        "        #Preprocessing dan augmentasi\n",
        "        augmented_images = preprocess_image_manual(image_path)\n",
        "\n",
        "        #Ekstraksi fitur untuk setiap gambar augmented\n",
        "        for augmented_image in augmented_images:\n",
        "            feature_vector = extract_features(augmented_image)\n",
        "            features.append(feature_vector)\n",
        "            labels.append(label)"
      ],
      "metadata": {
        "id": "9Hf3EKPbkuKE"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy, precision, recall, f1 = classify_images(features, labels)"
      ],
      "metadata": {
        "id": "zHEQMTJhKweN"
      },
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Recall: {recall * 100:.2f}%\")\n",
        "print(f\"F1-Score: {f1 * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J7ag1rC2K5RD",
        "outputId": "ba45d940-2a7e-49c3-cd78-cc4566577281"
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 90.21%\n",
            "Precision: 90.21%\n",
            "Recall: 90.21%\n",
            "F1-Score: 88.59%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Eksperimen 2"
      ],
      "metadata": {
        "id": "HaNggagfqRNt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan tuning hyperparamter pada model menggunakan GridSearchCV"
      ],
      "metadata": {
        "id": "AHygKaW9jNAC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV"
      ],
      "metadata": {
        "id": "SUQzorEhqTbb"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter tuning menggunakan GridSearchCV\n",
        "def hyperparameter_tuning(features, labels):\n",
        "    #Split data (80% training, 20% testing)\n",
        "    X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.2, random_state=42)\n",
        "\n",
        "    #Parameter grid untuk GridSearchCV\n",
        "    param_grid = {\n",
        "        'n_estimators': [50, 100, 200],  # Jumlah pohon\n",
        "        'max_depth': [None, 10, 20, 30],  # Kedalaman maksimum\n",
        "        'min_samples_split': [2, 5, 10],  # Minimum sampel untuk split\n",
        "        'min_samples_leaf': [1, 2, 4],  # Minimum sampel di leaf node\n",
        "        'max_features': ['sqrt', 'log2', None]  # Jumlah fitur untuk split\n",
        "    }\n",
        "\n",
        "    #Random Forest Classifier\n",
        "    rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "    #Grid Search dengan cross-validation\n",
        "    grid_search = GridSearchCV(estimator=rf, param_grid=param_grid, cv=5, scoring='accuracy', verbose=2, n_jobs=-1)\n",
        "    grid_search.fit(X_train, y_train)\n",
        "\n",
        "    #Best Parameters\n",
        "    print(\"Best Parameters:\", grid_search.best_params_)\n",
        "\n",
        "    #Evaluate model dengan parameter terbaik\n",
        "    best_model = grid_search.best_estimator_\n",
        "    y_pred = best_model.predict(X_test)\n",
        "\n",
        "    #Metrik Evaluasi\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    precision = precision_score(y_test, y_pred, average='weighted')\n",
        "    recall = recall_score(y_test, y_pred, average='weighted')\n",
        "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
        "\n",
        "    return accuracy, precision, recall, f1, grid_search.best_params_"
      ],
      "metadata": {
        "id": "KNT1fSquPwu3"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_path = \"/content/drive/MyDrive/Cocoa Ripeness Dataset\"\n",
        "categories = ['mentah', 'matang', 'terlalu_matang']\n",
        "\n",
        "features = []\n",
        "labels = []\n",
        "#Pre-process and extract features untuk semua citra\n",
        "for category in categories:\n",
        "    category_path = os.path.join(dataset_path, category)\n",
        "    label = categories.index(category)\n",
        "\n",
        "    for image_name in os.listdir(category_path):\n",
        "        image_path = os.path.join(category_path, image_name)\n",
        "\n",
        "        #Preprocessing dan augmentasi\n",
        "        augmented_images = preprocess_image_manual(image_path)\n",
        "\n",
        "        #Ekstraksi fitur untuk setiap gambar augmented\n",
        "        for augmented_image in augmented_images:\n",
        "            feature_vector = extract_features(augmented_image)\n",
        "            features.append(feature_vector)\n",
        "            labels.append(label)"
      ],
      "metadata": {
        "id": "yoVzzKV9QADV"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Konversi fitur dan label ke numpy array\n",
        "features, labels = np.array(features), np.array(labels)"
      ],
      "metadata": {
        "id": "vEK-aI3LQmbZ"
      },
      "execution_count": 82,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Hyperparameter Tuning and Evaluasi\n",
        "accuracy, precision, recall, f1, best_params = hyperparameter_tuning(features, labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtqp4o09eGwG",
        "outputId": "f94f21d9-5f3f-468a-9987-b6d8c436b7e1"
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
            "Best Parameters: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"\\nHasil Evaluasi Model Setelah Hyperparameter Tuning:\")\n",
        "print(f\"Best Parameters: {best_params}\")\n",
        "print(f\"Accuracy: {accuracy * 100:.2f}%\")\n",
        "print(f\"Precision: {precision * 100:.2f}%\")\n",
        "print(f\"Recall: {recall * 100:.2f}%\")\n",
        "print(f\"F1-Score: {f1 * 100:.2f}%\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rxU1JSJjQsBK",
        "outputId": "9eb4a74e-4e49-4396-ad8b-39c526abc278"
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Hasil Evaluasi Model Setelah Hyperparameter Tuning:\n",
            "Best Parameters: {'max_depth': None, 'max_features': None, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 50}\n",
            "Accuracy: 91.96%\n",
            "Precision: 91.83%\n",
            "Recall: 91.96%\n",
            "F1-Score: 91.05%\n"
          ]
        }
      ]
    }
  ]
}